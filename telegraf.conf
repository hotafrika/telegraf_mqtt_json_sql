[global_tags]

# Configuration for telegraf agent
# Оставляю эту секцию agent для дальнейшего конфигурирования всего агента.
[agent]
  ## Default data collection interval for all inputs
  # Как часто сборщик читает метрики из источников
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "µs"), "ms", "s".
  precision = ""

  ## Log at debug level.
  #debug = true
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  #logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  #logfile = "/var/log/telegraf/telegraf.log"

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  logfile_rotation_interval = "0d"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  logfile_rotation_max_size = "10MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################


# Send metrics to SQL Database
[[outputs.sql]]
	## Database driver
	## Valid options: mssql (Microsoft SQL Server), mysql (MySQL), pgx (Postgres), sqlite (SQLite3), snowflake (snowflake.com)
	driver = "pgx"

	## Data source name. Here we use datasource format for pgx
	## Необходимо выставить свои значения пользователя, пароля, хоста, порта и имени базы данных.
	## example data_source_name = "postgres://{user}:{password}@{hostname}:{port}/{database}"
	data_source_name = "postgres://mqttuser:mqttpass@127.0.0.1:5432/mqttdata"

	## Timestamp column name
	## Используем поле timestamp как поле, куда будет писаться время сбора метрик
	## По умолчанию берется время сбора метрики из источника, но мы переопределим это ниже в блоке JSON
	timestamp_column = "timestamp"

	## Table creation template
	## Указываем запрос, который создаст таблицу, если она не существует
	table_template = "CREATE TABLE metrics(device_id varchar(17) not null, timestamp timestamp not null, value float not null, type smallint not null)"
	#table_template = "CREATE TABLE metrics ({COLUMNS})"

	## Table existence check template
	## Запрос-проверка существует ли таблица
	table_exists_template = "SELECT 1 FROM metrics LIMIT 1"

	## Initialization SQL. We don't use it but I will leave it for future.
	# init_sql = ""

	## Metric type to SQL type conversion
	## The values on the left are the data types Telegraf has and the values on
	## the right are the data types Telegraf will use when sending to a database.
	##
	## The database values used must be data types the destination database
	## understands. It is up to the user to ensure that the selected data type is
	## available in the database they are using. Refer to your database
	## documentation for what data types are available and supported.

	[outputs.sql.convert]
	## Указываем, какие типы данных использовать telegraf для записи в Posgresql.
	## Если это не указать, то будет пытаться записать DOUBLE, а такого типа нет в PG.
	real = "REAL"

###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################
# Read metrics from MQTT topic(s)
[[inputs.mqtt_consumer]]
	## Broker URLs for the MQTT server or cluster.  To connect to multiple
	## clusters or standalone servers, use a separate plugin instance.
	## example: servers = ["tcp://localhost:1883"]
	## Тут необходимо указать хост и порт для MQTT сервера.
	servers = ["tcp://127.0.0.1:1883"]

	## Topics that will be subscribed to.
	## Указываем топик, откуда читаеются метрики.
	topics = [
		"house/sensors/data",
	]

	# To delete unnecessary 
	## Исключаем ненужные поля, которые вставляются в метрики по умолчанию.
	tagexclude = [
		"host",
		"topic",
	]

	## QoS policy for messages
	##   0 = at most once
	##   1 = at least once
	##   2 = exactly once
	##
	## When using a QoS of 1 or 2, you should enable persistent_session to allow
	## resuming unacknowledged messages.
	# qos = 0

	## Connection timeout for initial connection in seconds
	# connection_timeout = "30s"

	## Maximum messages to read from the broker that have not been written by an
	## output.  For best throughput set based on the number of metrics within
	## each message and the size of the output's metric_batch_size.
	##
	## For example, if each message from the queue contains 10 metrics and the
	## output metric_batch_size is 1000, setting this to 100 will ensure that a
	## full batch is collected and the write is triggered immediately without
	## waiting until the next flush_interval.
	# max_undelivered_messages = 1000

	## Persistent session disables clearing of the client session on connection.
	## In order for this option to work you must also set client_id to identify
	## the client.  To receive messages that arrived while the client is offline,
	## also set the qos option to 1 or 2 and don't forget to also set the QoS when
	## publishing.
	# persistent_session = false

	## If unset, a random client ID will be generated.
	# client_id = ""

	## Username and password to connect MQTT server.
	# username = "telegraf"
	# password = "metricsmetricsmetricsmetrics"

	## Optional TLS Config
	# tls_ca = "/etc/telegraf/ca.pem"
	# tls_cert = "/etc/telegraf/cert.pem"
	# tls_key = "/etc/telegraf/key.pem"

	## Use TLS but skip chain & host verification
	# insecure_skip_verify = false

	## Data format to consume.
	## Each data format has its own unique set of configuration options, read
	## more about them here:
	## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md

	## Указываем формат, в котором будем парсить данные источника.
	data_format = "json_v2"
	[[inputs.mqtt_consumer.json_v2]]
		## Указываем measurement_name в соответствии с именем таблицы в БД
		measurement_name = "metrics"
		## Указываем поле, из которого брать timestamp. Если этого не сделать, то по умолчанию будут браться время сбора метрик
		timestamp_path = "timestamp"
		timestamp_format = "unix"
		## Парсим поля: path - как оно лежит в JSON. rename - как будет писаться в таблице БД. и Тип.
		[[inputs.mqtt_consumer.json_v2.field]]
			path = "sensorID" # A string with valid GJSON path syntax to a non-array/non-object value
			rename = "device_id" # A string with a new name for the tag key
			type = "string" # A string specifying the type (int,uint,float,string,bool)
#		[[inputs.mqtt_consumer.json_v2.field]]
#			path = "timestamp" # A string with valid GJSON path syntax to a non-array/non-object value
#			rename = "timestamp" # A string with a new name for the tag key
#			type = "float" # A string specifying the type (int,uint,float,string,bool)
		[[inputs.mqtt_consumer.json_v2.field]]
			path = "value" # A string with valid GJSON path syntax to a non-array/non-object value
			rename = "value" # A string with a new name for the tag key
			type = "float" # A string specifying the type (int,uint,float,string,bool)
		[[inputs.mqtt_consumer.json_v2.field]]
			path = "type" # A string with valid GJSON path syntax to a non-array/non-object value
			rename = "type" # A string with a new name for the tag key
			type = "int" # A string specifying the type (int,uint,float,string,bool)
